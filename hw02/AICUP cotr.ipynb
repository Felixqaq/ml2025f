{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb7bdfe",
   "metadata": {},
   "source": [
    "# 1. 環境設定 (Windows 版本)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python 版本: {sys.version}\")\n",
    "!{sys.executable} -m pip install -U numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U ray==2.6.0\n",
    "import ray\n",
    "print(f\"Ray 版本: {ray.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61379479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"CUDA 可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 版本: {torch.version.cuda}\")\n",
    "    print(f\"GPU 裝置: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U monai==1.2.0\n",
    "import monai\n",
    "print(f\"MONAI 版本: {monai.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ml_collections\n",
    "!pip install timm\n",
    "!pip install einops\n",
    "!pip install scipy\n",
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dca1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kairaun/Sam.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝 Sam\n",
    "%cd Sam\n",
    "!dir\n",
    "!type pyproject.toml\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U --no-deps monailabel\n",
    "import monailabel\n",
    "print(f\"MONAILabel 版本: {monailabel.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"pydantic<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kairaun/CardiacSegV2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝環境 (Windows 版本)\n",
    "!pip install gdown==4.6.0\n",
    "\n",
    "# 注意：不直接安裝 requirements.txt，因為它包含舊版本的 PyTorch\n",
    "# 我們會手動安裝需要的套件\n",
    "print(\"正在安裝其他必要套件...\")\n",
    "\n",
    "# 讀取 requirements.txt 並過濾掉 PyTorch 相關套件\n",
    "import os\n",
    "req_file = os.path.join('CardiacSegV2', 'requirements.txt')\n",
    "if os.path.exists(req_file):\n",
    "    with open(req_file, 'r') as f:\n",
    "        packages = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n",
    "    \n",
    "    # 過濾掉已安裝或不相容的套件\n",
    "    skip_packages = ['torch', 'torchvision', 'torchaudio', 'monai', 'monailabel']\n",
    "    packages_to_install = [p for p in packages if not any(skip in p.lower() for skip in skip_packages)]\n",
    "    \n",
    "    print(f\"將安裝以下套件: {packages_to_install}\")\n",
    "    for pkg in packages_to_install:\n",
    "        try:\n",
    "            print(f\"安裝 {pkg}...\")\n",
    "            get_ipython().system(f'pip install {pkg}')\n",
    "        except Exception as e:\n",
    "            print(f\"警告: {pkg} 安裝失敗 - {e}\")\n",
    "else:\n",
    "    print(\"找不到 requirements.txt，跳過套件安裝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b46fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改程式碼以適應 Windows 路徑\n",
    "import os\n",
    "\n",
    "# 取得當前工作目錄\n",
    "workspace_dir = os.path.abspath('CardiacSegV2')\n",
    "print(f\"工作目錄: {workspace_dir}\")\n",
    "\n",
    "# 讀取並修改 setup_dir.py\n",
    "setup_dir_path = os.path.join(workspace_dir, 'setup_dir.py')\n",
    "with open(setup_dir_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 替換路徑 (使用 os.path.join 以支援 Windows)\n",
    "content = content.replace('/content/CardiacSegV2/', workspace_dir.replace('\\\\', '/') + '/')\n",
    "\n",
    "with open(setup_dir_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"setup_dir.py 已更新\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改 infer.py 和 tune.py\n",
    "import os\n",
    "\n",
    "workspace_dir = os.path.abspath('CardiacSegV2')\n",
    "\n",
    "# 修改 infer.py\n",
    "infer_path = os.path.join(workspace_dir, 'expers', 'infer.py')\n",
    "if os.path.exists(infer_path):\n",
    "    with open(infer_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    content = content.replace('sys.path.append(\"/content/CardiacSegV2\")', \n",
    "                             f'sys.path.append(\"{workspace_dir.replace(chr(92), chr(92)+chr(92))}\")')\n",
    "    with open(infer_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    print(\"infer.py 已更新\")\n",
    "\n",
    "# 修改 tune.py\n",
    "tune_path = os.path.join(workspace_dir, 'expers', 'tune.py')\n",
    "if os.path.exists(tune_path):\n",
    "    with open(tune_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    content = content.replace('sys.path.append(\"/content/CardiacSegV2\")', \n",
    "                             f'sys.path.append(\"{workspace_dir.replace(chr(92), chr(92)+chr(92))}\")')\n",
    "    content = content.replace('ray.init(runtime_env={\"working_dir\": \"/content/CardiacSegV2\"})',\n",
    "                             f'ray.init(runtime_env={{\"working_dir\": \"{workspace_dir.replace(chr(92), chr(92)+chr(92))}\"}})') \n",
    "    with open(tune_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    print(\"tune.py 已更新\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7789e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python CardiacSegV2\\setup_dir.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d546c4",
   "metadata": {},
   "source": [
    "# 2. 設定訓練參數\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45a3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工作目錄: d:\\Felix\\ML\\Code\\CardiacSegV2\n",
      "實驗目錄: d:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\exps\\cotr\\chgh\\tune_results\n",
      "資料目錄: d:\\Felix\\ML\\Code\\CardiacSegV2\\dataset\\chgh\n",
      "模型目錄: .\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 使用 Windows 風格的路徑\n",
    "workspace_dir = os.path.abspath('CardiacSegV2')\n",
    "model_name = 'cotr'\n",
    "data_name = 'chgh'\n",
    "exp_name = 'AICUP_training'\n",
    "data_dict_file_name = 'AICUP_training.json'\n",
    "\n",
    "# 設定實驗目錄\n",
    "root_exp_dir = os.path.join(workspace_dir, 'exps', 'exps', model_name, data_name, 'tune_results')\n",
    "\n",
    "# 設定資料目錄\n",
    "root_data_dir = os.path.join(workspace_dir, 'dataset', data_name)\n",
    "data_dir = root_data_dir\n",
    "\n",
    "# data dict json 路徑\n",
    "data_dicts_json = os.path.join(workspace_dir, 'exps', 'data_dicts', data_name, data_dict_file_name)\n",
    "\n",
    "# 設定模型、日誌、評估目錄\n",
    "model_dir = os.path.join('.', 'models')\n",
    "log_dir = os.path.join('.', 'logs')\n",
    "eval_dir = os.path.join('.', 'evals')\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "# 模型路徑\n",
    "best_checkpoint = os.path.join(model_dir, 'best_model.pth')\n",
    "final_checkpoint = os.path.join(model_dir, 'final_model.pth')\n",
    "\n",
    "# 建立根實驗目錄\n",
    "os.makedirs(root_exp_dir, exist_ok=True)\n",
    "\n",
    "print(f\"工作目錄: {workspace_dir}\")\n",
    "print(f\"實驗目錄: {root_exp_dir}\")\n",
    "print(f\"資料目錄: {data_dir}\")\n",
    "print(f\"模型目錄: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bdbcc0",
   "metadata": {},
   "source": [
    "# 3. 正式訓練\n",
    "\n",
    "執行模型訓練，訓練參數可以根據需要調整。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b315fa1",
   "metadata": {},
   "source": [
    "cd D:\\Felix\\ML\\Code\\CardiacSegV2\n",
    "\n",
    "python expers/tune.py --tune_mode=train --exp_name=AICUP_training --data_name=chgh --data_dir=D:\\Felix\\ML\\Code\\CardiacSegV2\\dataset\\chgh --root_exp_dir=D:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\exps\\unet3d\\chgh\\tune_results --model_name=unet3d --model_dir=.\\models --log_dir=.\\logs --eval_dir=.\\evals --start_epoch=0 --val_every=5 --max_early_stop_count=2 --max_epoch=20 --data_dicts_json=D:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\data_dicts\\chgh\\AICUP_training.json --pin_memory --out_channels=4 --patch_size=4 --feature_size=48 --drop_rate=0.1 --depths 3 3 9 3 --kernel_size 7 --exp_rate 4 --norm_name=layer --a_min=-42 --a_max=423 --space_x=0.7 --space_y=0.7 --space_z=1.0 --roi_x=128 --roi_y=128 --roi_z=120 --optim=AdamW --lr=5e-4 --weight_decay=5e-4 --checkpoint=.\\models\\final_model.pth --use_init_weights --infer_post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63b17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "當前工作目錄: d:\\Felix\\ML\\Code\\CardiacSegV2\n",
      "開始訓練...\n",
      "\n",
      "執行命令:\n",
      "d:\\Felix\\ML\\Code\\.conda\\python.exe expers/tune.py --tune_mode=train --exp_name=AICUP_training --data_name=chgh --data_dir=d:\\Felix\\ML\\Code\\CardiacSegV2\\dataset\\chgh --root_exp_dir=d:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\exps\\cotr\\chgh\\tune_results --model_name=cotr --model_dir=.\\models --log_dir=.\\logs --eval_dir=.\\evals --start_epoch=0 --val_every=5 --max_early_stop_count=2 --max_epoch=20 --data_dicts_json=d:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\data_dicts\\chgh\\AICUP_training.json --pin_memory --out_channels=4 --patch_size=4 --feature_size=48 --drop_rate=0.1 --depths 3 3 9 3 --kernel_size 7 --exp_rate 4 --norm_name=layer --a_min=-42 --a_max=423 --space_x=0.7 --space_y=0.7 --space_z=1.0 --roi_x=128 --roi_y=128 --roi_z=120 --optim=AdamW --lr=5e-4 --weight_decay=5e-4 --checkpoint=.\\models\\final_model.pth --use_init_weights --infer_post_process\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "Setting a `RunConfig.local_dir` is deprecated and will be removed in the future. If you are not using remote storage,set the `RunConfig.storage_path` instead. Otherwise, set the`RAY_AIR_LOCAL_CACHE_DIR` environment variable to control the local cache location.\n",
      "2025-10-16 21:35:12,226\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2025-10-16 21:35:13,734\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "2025-10-16 21:35:13,735\tINFO tune.py:666 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-10-16 21:35:13,740\tINFO tensorboardx.py:178 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2025-10-16 21:35:13,740\tWARNING callback.py:144 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2025-10-16 21:35:13,741\tWARNING tune.py:997 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n",
      "╭────────────────────────────────────────────────────────╮\n",
      "│ Configuration for experiment     AICUP_training        │\n",
      "├────────────────────────────────────────────────────────┤\n",
      "│ Search algorithm                 BasicVariantGenerator │\n",
      "│ Scheduler                        FIFOScheduler         │\n",
      "│ Number of trials                 1                     │\n",
      "╰────────────────────────────────────────────────────────╯\n",
      "\n",
      "View detailed results here: d://\\Felix\\ML\\Code\\CardiacSegV2\\exps\\exps\\cotr\\chgh\\tune_results\\AICUP_training\n",
      "\n",
      "Trial status: 1 PENDING\n",
      "Current time: 2025-10-16 21:35:13. Total running time: 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   PENDING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=31264)\u001b[0m Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "\u001b[2m\u001b[36m(pid=31264)\u001b[0m Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "Training started with configuration:\n",
      "╭────────────────────────────────────╮\n",
      "│ Training config                    │\n",
      "├────────────────────────────────────┤\n",
      "│ exp/exp             AICUP_training │\n",
      "╰────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m a_max 423.0\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m a_min -42.0\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m space_x 0.7\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m roi_x 128\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m lr 0.0005\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m weight_decay 0.0005\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m warmup_epochs 50\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m max_epochs 20\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m cuda is available\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m model: cotr\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m   + Number of Backbone Params: 20.50(e6)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m   + Number of Transformer Params: 9.32(e6)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m <class 'monai.transforms.utility.dictionary.AddChanneld'>: Class `AddChanneld` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirstd instead with `channel_dim='no_channel'`.\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m monai.transforms.utility.dictionary EnsureChannelFirstd.__init__:meta_keys: Argument `meta_keys` has been deprecated since version 0.9. not needed if image is type `MetaTensor`.\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m loss: dice ce loss\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m optimzer: AdamW\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m {'lr': 0.0005, 'weight_decay': 0.0005}\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m load json from d:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\data_dicts\\chgh\\AICUP_training.json\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m train files (9): ['patient0011', 'patient0012', 'patient0013', 'patient0014', 'patient0015', 'patient0016', 'patient0017', 'patient0018', 'patient0019']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m val files (3): ['patient0048', 'patient0049', 'patient0050']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m test files (3): ['patient0001', 'patient0002', 'patient0003']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m load train dataset ...\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Using MONAI Cache Dataset\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  11%|█         | 1/9 [00:04<00:34,  4.33s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  22%|██▏       | 2/9 [00:06<00:20,  2.97s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  33%|███▎      | 3/9 [00:10<00:19,  3.33s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  44%|████▍     | 4/9 [00:10<00:11,  2.36s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  56%|█████▌    | 5/9 [00:15<00:12,  3.04s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  67%|██████▋   | 6/9 [00:18<00:08,  2.96s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  78%|███████▊  | 7/9 [00:20<00:05,  2.96s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  89%|████████▉ | 8/9 [00:22<00:02,  2.54s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:35:43. Total running time: 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset: 100%|██████████| 9/9 [00:27<00:00,  3.12s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:27<00:00,  3.00s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m load val dataset ...\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Using MONAI Cache Dataset\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset:  33%|███▎      | 1/3 [00:06<00:12,  6.24s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Loading dataset: 100%|██████████| 3/3 [00:10<00:00,  3.36s/it]\n",
      "Loading dataset: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (0 Steps) (loss=8.44649):   0%|          | 0/9 [00:10<?, ?it/s]\n",
      "[Epoch 0] Training (0 Steps) (loss=8.44649):  11%|█         | 1/9 [00:10<01:21, 10.17s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (1 Steps) (loss=4.00954):  11%|█         | 1/9 [00:10<01:21, 10.17s/it]\n",
      "[Epoch 0] Training (1 Steps) (loss=4.00954):  22%|██▏       | 2/9 [00:10<00:32,  4.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (2 Steps) (loss=2.27673):  22%|██▏       | 2/9 [00:11<00:32,  4.66s/it]\n",
      "[Epoch 0] Training (2 Steps) (loss=2.27673):  33%|███▎      | 3/9 [00:11<00:17,  2.91s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (3 Steps) (loss=2.00162):  33%|███▎      | 3/9 [00:12<00:17,  2.91s/it]\n",
      "[Epoch 0] Training (3 Steps) (loss=2.00162):  44%|████▍     | 4/9 [00:12<00:10,  2.10s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (4 Steps) (loss=1.79890):  44%|████▍     | 4/9 [00:13<00:10,  2.10s/it]\n",
      "[Epoch 0] Training (4 Steps) (loss=1.79890):  56%|█████▌    | 5/9 [00:13<00:06,  1.65s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (5 Steps) (loss=1.52999):  56%|█████▌    | 5/9 [00:14<00:06,  1.65s/it]\n",
      "[Epoch 0] Training (5 Steps) (loss=1.52999):  67%|██████▋   | 6/9 [00:14<00:04,  1.37s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (6 Steps) (loss=1.88563):  67%|██████▋   | 6/9 [00:15<00:04,  1.37s/it]\n",
      "[Epoch 0] Training (6 Steps) (loss=1.88563):  78%|███████▊  | 7/9 [00:15<00:02,  1.19s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (7 Steps) (loss=1.49647):  78%|███████▊  | 7/9 [00:16<00:02,  1.19s/it]\n",
      "[Epoch 0] Training (7 Steps) (loss=1.49647):  89%|████████▉ | 8/9 [00:16<00:01,  1.09s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:36:13. Total running time: 1min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (8 Steps) (loss=1.47233):  89%|████████▉ | 8/9 [00:16<00:01,  1.09s/it]\n",
      "[Epoch 0] Training (8 Steps) (loss=1.47233): 100%|██████████| 9/9 [00:16<00:00,  1.02s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 0] Training (8 Steps) (loss=1.47233): 100%|██████████| 9/9 [00:17<00:00,  1.95s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (9 Steps) (loss=1.45366):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 1] Training (9 Steps) (loss=1.45366):  11%|█         | 1/9 [00:09<01:17,  9.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (10 Steps) (loss=1.43111):  11%|█         | 1/9 [00:10<01:17,  9.66s/it]\n",
      "[Epoch 1] Training (10 Steps) (loss=1.43111):  22%|██▏       | 2/9 [00:10<00:30,  4.34s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (11 Steps) (loss=1.26486):  22%|██▏       | 2/9 [00:10<00:30,  4.34s/it]\n",
      "[Epoch 1] Training (11 Steps) (loss=1.26486):  33%|███▎      | 3/9 [00:10<00:15,  2.64s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (12 Steps) (loss=1.33747):  33%|███▎      | 3/9 [00:11<00:15,  2.64s/it]\n",
      "[Epoch 1] Training (12 Steps) (loss=1.33747):  44%|████▍     | 4/9 [00:11<00:09,  1.85s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (13 Steps) (loss=1.06524):  44%|████▍     | 4/9 [00:12<00:09,  1.85s/it]\n",
      "[Epoch 1] Training (13 Steps) (loss=1.06524):  56%|█████▌    | 5/9 [00:12<00:05,  1.40s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (14 Steps) (loss=1.25011):  56%|█████▌    | 5/9 [00:12<00:05,  1.40s/it]\n",
      "[Epoch 1] Training (14 Steps) (loss=1.25011):  67%|██████▋   | 6/9 [00:12<00:03,  1.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (15 Steps) (loss=1.27143):  67%|██████▋   | 6/9 [00:13<00:03,  1.14s/it]\n",
      "[Epoch 1] Training (15 Steps) (loss=1.27143):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (16 Steps) (loss=1.33390):  78%|███████▊  | 7/9 [00:14<00:01,  1.03it/s]\n",
      "[Epoch 1] Training (16 Steps) (loss=1.33390):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (17 Steps) (loss=1.45564):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 1] Training (17 Steps) (loss=1.45564): 100%|██████████| 9/9 [00:14<00:00,  1.27it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 1] Training (17 Steps) (loss=1.45564): 100%|██████████| 9/9 [00:15<00:00,  1.70s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (18 Steps) (loss=1.16986):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 2] Training (18 Steps) (loss=1.16986):  11%|█         | 1/9 [00:09<01:15,  9.41s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (19 Steps) (loss=1.06123):  11%|█         | 1/9 [00:10<01:15,  9.41s/it]\n",
      "[Epoch 2] Training (19 Steps) (loss=1.06123):  22%|██▏       | 2/9 [00:10<00:29,  4.25s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (20 Steps) (loss=1.00585):  22%|██▏       | 2/9 [00:10<00:29,  4.25s/it]\n",
      "[Epoch 2] Training (20 Steps) (loss=1.00585):  33%|███▎      | 3/9 [00:10<00:15,  2.59s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (21 Steps) (loss=1.47907):  33%|███▎      | 3/9 [00:11<00:15,  2.59s/it]\n",
      "[Epoch 2] Training (21 Steps) (loss=1.47907):  44%|████▍     | 4/9 [00:11<00:09,  1.82s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (22 Steps) (loss=1.16346):  44%|████▍     | 4/9 [00:11<00:09,  1.82s/it]\n",
      "[Epoch 2] Training (22 Steps) (loss=1.16346):  56%|█████▌    | 5/9 [00:11<00:05,  1.39s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (23 Steps) (loss=1.26492):  56%|█████▌    | 5/9 [00:12<00:05,  1.39s/it]\n",
      "[Epoch 2] Training (23 Steps) (loss=1.26492):  67%|██████▋   | 6/9 [00:12<00:03,  1.13s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (24 Steps) (loss=1.01576):  67%|██████▋   | 6/9 [00:13<00:03,  1.13s/it]\n",
      "[Epoch 2] Training (24 Steps) (loss=1.01576):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:36:44. Total running time: 1min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (25 Steps) (loss=1.03048):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "[Epoch 2] Training (25 Steps) (loss=1.03048):  89%|████████▉ | 8/9 [00:13<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (26 Steps) (loss=1.18155):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 2] Training (26 Steps) (loss=1.18155): 100%|██████████| 9/9 [00:14<00:00,  1.27it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 2] Training (26 Steps) (loss=1.18155): 100%|██████████| 9/9 [00:15<00:00,  1.68s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (27 Steps) (loss=1.04738):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 3] Training (27 Steps) (loss=1.04738):  11%|█         | 1/9 [00:09<01:15,  9.41s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (28 Steps) (loss=1.10017):  11%|█         | 1/9 [00:10<01:15,  9.41s/it]\n",
      "[Epoch 3] Training (28 Steps) (loss=1.10017):  22%|██▏       | 2/9 [00:10<00:29,  4.24s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (29 Steps) (loss=0.97612):  22%|██▏       | 2/9 [00:10<00:29,  4.24s/it]\n",
      "[Epoch 3] Training (29 Steps) (loss=0.97612):  33%|███▎      | 3/9 [00:10<00:15,  2.59s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (30 Steps) (loss=0.97044):  33%|███▎      | 3/9 [00:11<00:15,  2.59s/it]\n",
      "[Epoch 3] Training (30 Steps) (loss=0.97044):  44%|████▍     | 4/9 [00:11<00:09,  1.81s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (31 Steps) (loss=1.47644):  44%|████▍     | 4/9 [00:11<00:09,  1.81s/it]\n",
      "[Epoch 3] Training (31 Steps) (loss=1.47644):  56%|█████▌    | 5/9 [00:11<00:05,  1.38s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (32 Steps) (loss=1.16664):  56%|█████▌    | 5/9 [00:12<00:05,  1.38s/it]\n",
      "[Epoch 3] Training (32 Steps) (loss=1.16664):  67%|██████▋   | 6/9 [00:12<00:03,  1.12s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (33 Steps) (loss=1.39483):  67%|██████▋   | 6/9 [00:13<00:03,  1.12s/it]\n",
      "[Epoch 3] Training (33 Steps) (loss=1.39483):  78%|███████▊  | 7/9 [00:13<00:01,  1.04it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (34 Steps) (loss=1.25157):  78%|███████▊  | 7/9 [00:13<00:01,  1.04it/s]\n",
      "[Epoch 3] Training (34 Steps) (loss=1.25157):  89%|████████▉ | 8/9 [00:13<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (35 Steps) (loss=0.95978):  89%|████████▉ | 8/9 [00:14<00:00,  1.18it/s]\n",
      "[Epoch 3] Training (35 Steps) (loss=0.95978): 100%|██████████| 9/9 [00:14<00:00,  1.29it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 3] Training (35 Steps) (loss=0.95978): 100%|██████████| 9/9 [00:15<00:00,  1.67s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (36 Steps) (loss=1.34685):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 4] Training (36 Steps) (loss=1.34685):  11%|█         | 1/9 [00:09<01:16,  9.58s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (37 Steps) (loss=1.46095):  11%|█         | 1/9 [00:10<01:16,  9.58s/it]\n",
      "[Epoch 4] Training (37 Steps) (loss=1.46095):  22%|██▏       | 2/9 [00:10<00:30,  4.39s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (38 Steps) (loss=1.22134):  22%|██▏       | 2/9 [00:11<00:30,  4.39s/it]\n",
      "[Epoch 4] Training (38 Steps) (loss=1.22134):  33%|███▎      | 3/9 [00:11<00:16,  2.74s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (39 Steps) (loss=0.85415):  33%|███▎      | 3/9 [00:11<00:16,  2.74s/it]\n",
      "[Epoch 4] Training (39 Steps) (loss=0.85415):  44%|████▍     | 4/9 [00:11<00:09,  1.96s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (40 Steps) (loss=1.08278):  44%|████▍     | 4/9 [00:12<00:09,  1.96s/it]\n",
      "[Epoch 4] Training (40 Steps) (loss=1.08278):  56%|█████▌    | 5/9 [00:12<00:06,  1.53s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:37:14. Total running time: 2min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (41 Steps) (loss=1.36721):  56%|█████▌    | 5/9 [00:13<00:06,  1.53s/it]\n",
      "[Epoch 4] Training (41 Steps) (loss=1.36721):  67%|██████▋   | 6/9 [00:13<00:03,  1.27s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (42 Steps) (loss=1.15503):  67%|██████▋   | 6/9 [00:14<00:03,  1.27s/it]\n",
      "[Epoch 4] Training (42 Steps) (loss=1.15503):  78%|███████▊  | 7/9 [00:14<00:02,  1.11s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (43 Steps) (loss=0.98093):  78%|███████▊  | 7/9 [00:14<00:02,  1.11s/it]\n",
      "[Epoch 4] Training (43 Steps) (loss=0.98093):  89%|████████▉ | 8/9 [00:14<00:01,  1.00s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (44 Steps) (loss=0.99879):  89%|████████▉ | 8/9 [00:15<00:01,  1.00s/it]\n",
      "[Epoch 4] Training (44 Steps) (loss=0.99879): 100%|██████████| 9/9 [00:15<00:00,  1.08it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 4] Training (44 Steps) (loss=0.99879): 100%|██████████| 9/9 [00:16<00:00,  1.82s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (45 Steps) (loss=0.95217):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 5] Training (45 Steps) (loss=0.95217):  11%|█         | 1/9 [00:09<01:18,  9.76s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (46 Steps) (loss=1.15211):  11%|█         | 1/9 [00:10<01:18,  9.76s/it]\n",
      "[Epoch 5] Training (46 Steps) (loss=1.15211):  22%|██▏       | 2/9 [00:10<00:30,  4.39s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (47 Steps) (loss=1.38353):  22%|██▏       | 2/9 [00:11<00:30,  4.39s/it]\n",
      "[Epoch 5] Training (47 Steps) (loss=1.38353):  33%|███▎      | 3/9 [00:11<00:16,  2.67s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (48 Steps) (loss=0.83945):  33%|███▎      | 3/9 [00:11<00:16,  2.67s/it]\n",
      "[Epoch 5] Training (48 Steps) (loss=0.83945):  44%|████▍     | 4/9 [00:11<00:09,  1.86s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (49 Steps) (loss=1.17274):  44%|████▍     | 4/9 [00:12<00:09,  1.86s/it]\n",
      "[Epoch 5] Training (49 Steps) (loss=1.17274):  56%|█████▌    | 5/9 [00:12<00:05,  1.42s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (50 Steps) (loss=1.10779):  56%|█████▌    | 5/9 [00:12<00:05,  1.42s/it]\n",
      "[Epoch 5] Training (50 Steps) (loss=1.10779):  67%|██████▋   | 6/9 [00:12<00:03,  1.15s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (51 Steps) (loss=0.98617):  67%|██████▋   | 6/9 [00:13<00:03,  1.15s/it]\n",
      "[Epoch 5] Training (51 Steps) (loss=0.98617):  78%|███████▊  | 7/9 [00:13<00:01,  1.02it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (52 Steps) (loss=1.03959):  78%|███████▊  | 7/9 [00:14<00:01,  1.02it/s]\n",
      "[Epoch 5] Training (52 Steps) (loss=1.03959):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (53 Steps) (loss=1.15545):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 5] Training (53 Steps) (loss=1.15545): 100%|██████████| 9/9 [00:14<00:00,  1.26it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 5] Training (53 Steps) (loss=1.15545): 100%|██████████| 9/9 [00:15<00:00,  1.72s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (54 / 10 Steps):   0%|          | 0/3 [00:06<?, ?it/s]         \n",
      "Validate (54 / 10 Steps):  33%|███▎      | 1/3 [00:06<00:12,  6.02s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (54 / 10 Steps):  33%|███▎      | 1/3 [00:07<00:12,  6.02s/it]\n",
      "Validate (54 / 10 Steps):  67%|██████▋   | 2/3 [00:07<00:03,  3.32s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (54 / 10 Steps):  67%|██████▋   | 2/3 [00:08<00:03,  3.32s/it]\n",
      "Validate (54 / 10 Steps): 100%|██████████| 3/3 [00:08<00:00,  2.48s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (54 / 10 Steps): 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\best_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Best Model Was Saved ! Current Best Avg. Dice: 0.38882943987846375 Current Avg. Dice: 0.38882943987846375\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:37:44. Total running time: 2min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                  │\n",
      "├────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'} │\n",
      "╰────────────────────────────────────────────────────╯\n",
      "\n",
      "Training finished iteration 1 at 2025-10-16 21:37:44. Total running time: 2min 30s\n",
      "╭──────────────────────────────╮\n",
      "│ Training result              │\n",
      "├──────────────────────────────┤\n",
      "│ time_this_iter_s     145.277 │\n",
      "│ time_total_s         145.277 │\n",
      "│ training_iteration         1 │\n",
      "│ esc                        0 │\n",
      "│ tt_dice                    0 │\n",
      "│ tt_iou                     0 │\n",
      "│ val_bst_acc          0.38883 │\n",
      "╰──────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\final_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.38882943987846375 Current Avg. Dice: 0.38882943987846375\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (54 Steps) (loss=1.05582):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 6] Training (54 Steps) (loss=1.05582):  11%|█         | 1/9 [00:09<01:15,  9.41s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (55 Steps) (loss=0.95206):  11%|█         | 1/9 [00:10<01:15,  9.41s/it]\n",
      "[Epoch 6] Training (55 Steps) (loss=0.95206):  22%|██▏       | 2/9 [00:10<00:30,  4.29s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (56 Steps) (loss=0.99766):  22%|██▏       | 2/9 [00:10<00:30,  4.29s/it]\n",
      "[Epoch 6] Training (56 Steps) (loss=0.99766):  33%|███▎      | 3/9 [00:10<00:15,  2.65s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (57 Steps) (loss=1.34255):  33%|███▎      | 3/9 [00:11<00:15,  2.65s/it]\n",
      "[Epoch 6] Training (57 Steps) (loss=1.34255):  44%|████▍     | 4/9 [00:11<00:09,  1.88s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (58 Steps) (loss=0.84950):  44%|████▍     | 4/9 [00:12<00:09,  1.88s/it]\n",
      "[Epoch 6] Training (58 Steps) (loss=0.84950):  56%|█████▌    | 5/9 [00:12<00:05,  1.46s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (59 Steps) (loss=0.97520):  56%|█████▌    | 5/9 [00:12<00:05,  1.46s/it]\n",
      "[Epoch 6] Training (59 Steps) (loss=0.97520):  67%|██████▋   | 6/9 [00:12<00:03,  1.20s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (60 Steps) (loss=0.90745):  67%|██████▋   | 6/9 [00:13<00:03,  1.20s/it]\n",
      "[Epoch 6] Training (60 Steps) (loss=0.90745):  78%|███████▊  | 7/9 [00:13<00:02,  1.03s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (61 Steps) (loss=0.95632):  78%|███████▊  | 7/9 [00:14<00:02,  1.03s/it]\n",
      "[Epoch 6] Training (61 Steps) (loss=0.95632):  89%|████████▉ | 8/9 [00:14<00:00,  1.09it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (62 Steps) (loss=1.04123):  89%|████████▉ | 8/9 [00:14<00:00,  1.09it/s]\n",
      "[Epoch 6] Training (62 Steps) (loss=1.04123): 100%|██████████| 9/9 [00:14<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 6] Training (62 Steps) (loss=1.04123): 100%|██████████| 9/9 [00:15<00:00,  1.74s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (63 Steps) (loss=0.94925):   0%|          | 0/9 [00:10<?, ?it/s]\n",
      "[Epoch 7] Training (63 Steps) (loss=0.94925):  11%|█         | 1/9 [00:10<01:20, 10.11s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (64 Steps) (loss=1.04792):  11%|█         | 1/9 [00:11<01:20, 10.11s/it]\n",
      "[Epoch 7] Training (64 Steps) (loss=1.04792):  22%|██▏       | 2/9 [00:11<00:35,  5.02s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (65 Steps) (loss=0.88186):  22%|██▏       | 2/9 [00:13<00:35,  5.02s/it]\n",
      "[Epoch 7] Training (65 Steps) (loss=0.88186):  33%|███▎      | 3/9 [00:13<00:20,  3.42s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:38:14. Total running time: 3min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        1            145.277           0          0        0.388829       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (66 Steps) (loss=0.87622):  33%|███▎      | 3/9 [00:14<00:20,  3.42s/it]\n",
      "[Epoch 7] Training (66 Steps) (loss=0.87622):  44%|████▍     | 4/9 [00:14<00:12,  2.52s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (67 Steps) (loss=0.90927):  44%|████▍     | 4/9 [00:15<00:12,  2.52s/it]\n",
      "[Epoch 7] Training (67 Steps) (loss=0.90927):  56%|█████▌    | 5/9 [00:15<00:08,  2.02s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (68 Steps) (loss=0.93358):  56%|█████▌    | 5/9 [00:16<00:08,  2.02s/it]\n",
      "[Epoch 7] Training (68 Steps) (loss=0.93358):  67%|██████▋   | 6/9 [00:16<00:05,  1.71s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (69 Steps) (loss=1.02392):  67%|██████▋   | 6/9 [00:17<00:05,  1.71s/it]\n",
      "[Epoch 7] Training (69 Steps) (loss=1.02392):  78%|███████▊  | 7/9 [00:17<00:03,  1.54s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (70 Steps) (loss=0.79140):  78%|███████▊  | 7/9 [00:18<00:03,  1.54s/it]\n",
      "[Epoch 7] Training (70 Steps) (loss=0.79140):  89%|████████▉ | 8/9 [00:18<00:01,  1.42s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (71 Steps) (loss=0.92090):  89%|████████▉ | 8/9 [00:20<00:01,  1.42s/it]\n",
      "[Epoch 7] Training (71 Steps) (loss=0.92090): 100%|██████████| 9/9 [00:20<00:00,  1.35s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 7] Training (71 Steps) (loss=0.92090): 100%|██████████| 9/9 [00:20<00:00,  2.30s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (72 Steps) (loss=0.94028):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 8] Training (72 Steps) (loss=0.94028):  11%|█         | 1/9 [00:09<01:16,  9.60s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (73 Steps) (loss=0.91448):  11%|█         | 1/9 [00:10<01:16,  9.60s/it]\n",
      "[Epoch 8] Training (73 Steps) (loss=0.91448):  22%|██▏       | 2/9 [00:10<00:30,  4.32s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (74 Steps) (loss=0.87632):  22%|██▏       | 2/9 [00:10<00:30,  4.32s/it]\n",
      "[Epoch 8] Training (74 Steps) (loss=0.87632):  33%|███▎      | 3/9 [00:10<00:15,  2.64s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (75 Steps) (loss=0.88943):  33%|███▎      | 3/9 [00:11<00:15,  2.64s/it]\n",
      "[Epoch 8] Training (75 Steps) (loss=0.88943):  44%|████▍     | 4/9 [00:11<00:09,  1.85s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (76 Steps) (loss=0.82354):  44%|████▍     | 4/9 [00:12<00:09,  1.85s/it]\n",
      "[Epoch 8] Training (76 Steps) (loss=0.82354):  56%|█████▌    | 5/9 [00:12<00:05,  1.41s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (77 Steps) (loss=0.84169):  56%|█████▌    | 5/9 [00:12<00:05,  1.41s/it]\n",
      "[Epoch 8] Training (77 Steps) (loss=0.84169):  67%|██████▋   | 6/9 [00:12<00:03,  1.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (78 Steps) (loss=0.94584):  67%|██████▋   | 6/9 [00:13<00:03,  1.14s/it]\n",
      "[Epoch 8] Training (78 Steps) (loss=0.94584):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (79 Steps) (loss=0.86650):  78%|███████▊  | 7/9 [00:14<00:01,  1.03it/s]\n",
      "[Epoch 8] Training (79 Steps) (loss=0.86650):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (80 Steps) (loss=0.83949):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 8] Training (80 Steps) (loss=0.83949): 100%|██████████| 9/9 [00:14<00:00,  1.26it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 8] Training (80 Steps) (loss=0.83949): 100%|██████████| 9/9 [00:15<00:00,  1.70s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:38:44. Total running time: 3min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        1            145.277           0          0        0.388829       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (81 Steps) (loss=0.86659):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 9] Training (81 Steps) (loss=0.86659):  11%|█         | 1/9 [00:09<01:14,  9.36s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (82 Steps) (loss=0.93747):  11%|█         | 1/9 [00:10<01:14,  9.36s/it]\n",
      "[Epoch 9] Training (82 Steps) (loss=0.93747):  22%|██▏       | 2/9 [00:10<00:29,  4.25s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (83 Steps) (loss=0.82551):  22%|██▏       | 2/9 [00:10<00:29,  4.25s/it]\n",
      "[Epoch 9] Training (83 Steps) (loss=0.82551):  33%|███▎      | 3/9 [00:10<00:15,  2.62s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (84 Steps) (loss=0.81796):  33%|███▎      | 3/9 [00:11<00:15,  2.62s/it]\n",
      "[Epoch 9] Training (84 Steps) (loss=0.81796):  44%|████▍     | 4/9 [00:11<00:09,  1.85s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (85 Steps) (loss=0.87671):  44%|████▍     | 4/9 [00:12<00:09,  1.85s/it]\n",
      "[Epoch 9] Training (85 Steps) (loss=0.87671):  56%|█████▌    | 5/9 [00:12<00:05,  1.42s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (86 Steps) (loss=0.99685):  56%|█████▌    | 5/9 [00:12<00:05,  1.42s/it]\n",
      "[Epoch 9] Training (86 Steps) (loss=0.99685):  67%|██████▋   | 6/9 [00:12<00:03,  1.17s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (87 Steps) (loss=0.86035):  67%|██████▋   | 6/9 [00:13<00:03,  1.17s/it]\n",
      "[Epoch 9] Training (87 Steps) (loss=0.86035):  78%|███████▊  | 7/9 [00:13<00:02,  1.00s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (88 Steps) (loss=0.74726):  78%|███████▊  | 7/9 [00:14<00:02,  1.00s/it]\n",
      "[Epoch 9] Training (88 Steps) (loss=0.74726):  89%|████████▉ | 8/9 [00:14<00:00,  1.12it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (89 Steps) (loss=0.71685):  89%|████████▉ | 8/9 [00:14<00:00,  1.12it/s]\n",
      "[Epoch 9] Training (89 Steps) (loss=0.71685): 100%|██████████| 9/9 [00:14<00:00,  1.21it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 9] Training (89 Steps) (loss=0.71685): 100%|██████████| 9/9 [00:15<00:00,  1.71s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (90 Steps) (loss=0.92526):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 10] Training (90 Steps) (loss=0.92526):  11%|█         | 1/9 [00:09<01:16,  9.52s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (91 Steps) (loss=0.87875):  11%|█         | 1/9 [00:10<01:16,  9.52s/it]\n",
      "[Epoch 10] Training (91 Steps) (loss=0.87875):  22%|██▏       | 2/9 [00:10<00:30,  4.29s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (92 Steps) (loss=0.76607):  22%|██▏       | 2/9 [00:10<00:30,  4.29s/it]\n",
      "[Epoch 10] Training (92 Steps) (loss=0.76607):  33%|███▎      | 3/9 [00:10<00:15,  2.62s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (93 Steps) (loss=0.80312):  33%|███▎      | 3/9 [00:11<00:15,  2.62s/it]\n",
      "[Epoch 10] Training (93 Steps) (loss=0.80312):  44%|████▍     | 4/9 [00:11<00:09,  1.83s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (94 Steps) (loss=0.84479):  44%|████▍     | 4/9 [00:12<00:09,  1.83s/it]\n",
      "[Epoch 10] Training (94 Steps) (loss=0.84479):  56%|█████▌    | 5/9 [00:12<00:05,  1.40s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (95 Steps) (loss=0.79284):  56%|█████▌    | 5/9 [00:12<00:05,  1.40s/it]\n",
      "[Epoch 10] Training (95 Steps) (loss=0.79284):  67%|██████▋   | 6/9 [00:12<00:03,  1.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (96 Steps) (loss=0.81923):  67%|██████▋   | 6/9 [00:13<00:03,  1.14s/it]\n",
      "[Epoch 10] Training (96 Steps) (loss=0.81923):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (97 Steps) (loss=1.22876):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "[Epoch 10] Training (97 Steps) (loss=1.22876):  89%|████████▉ | 8/9 [00:13<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (98 Steps) (loss=0.91388):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 10] Training (98 Steps) (loss=0.91388): 100%|██████████| 9/9 [00:14<00:00,  1.27it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 10] Training (98 Steps) (loss=0.91388): 100%|██████████| 9/9 [00:15<00:00,  1.69s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (99 / 10 Steps):   0%|          | 0/3 [00:05<?, ?it/s]         \n",
      "Validate (99 / 10 Steps):  33%|███▎      | 1/3 [00:05<00:11,  5.94s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (99 / 10 Steps):  33%|███▎      | 1/3 [00:07<00:11,  5.94s/it]\n",
      "Validate (99 / 10 Steps):  67%|██████▋   | 2/3 [00:07<00:03,  3.29s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:39:14. Total running time: 4min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        1            145.277           0          0        0.388829       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (99 / 10 Steps):  67%|██████▋   | 2/3 [00:08<00:03,  3.29s/it]\n",
      "Validate (99 / 10 Steps): 100%|██████████| 3/3 [00:08<00:00,  2.47s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (99 / 10 Steps): 100%|██████████| 3/3 [00:09<00:00,  3.17s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\best_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Best Model Was Saved ! Current Best Avg. Dice: 0.46777477860450745 Current Avg. Dice: 0.46777477860450745\n",
      "Training finished iteration 2 at 2025-10-16 21:39:18. Total running time: 4min 4s\n",
      "╭──────────────────────────────╮\n",
      "│ Training result              │\n",
      "├──────────────────────────────┤\n",
      "│ time_this_iter_s     94.0214 │\n",
      "│ time_total_s         239.298 │\n",
      "│ training_iteration         2 │\n",
      "│ esc                        0 │\n",
      "│ tt_dice                    0 │\n",
      "│ tt_iou                     0 │\n",
      "│ val_bst_acc          0.46777 │\n",
      "╰──────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\final_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.46777477860450745 Current Avg. Dice: 0.46777477860450745\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (99 Steps) (loss=1.03808):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 11] Training (99 Steps) (loss=1.03808):  11%|█         | 1/9 [00:09<01:14,  9.30s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (100 Steps) (loss=0.96609):  11%|█         | 1/9 [00:09<01:14,  9.30s/it]\n",
      "[Epoch 11] Training (100 Steps) (loss=0.96609):  22%|██▏       | 2/9 [00:09<00:29,  4.20s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (101 Steps) (loss=0.84426):  22%|██▏       | 2/9 [00:10<00:29,  4.20s/it]\n",
      "[Epoch 11] Training (101 Steps) (loss=0.84426):  33%|███▎      | 3/9 [00:10<00:15,  2.56s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (102 Steps) (loss=1.01251):  33%|███▎      | 3/9 [00:11<00:15,  2.56s/it]\n",
      "[Epoch 11] Training (102 Steps) (loss=1.01251):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (103 Steps) (loss=1.07914):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "[Epoch 11] Training (103 Steps) (loss=1.07914):  56%|█████▌    | 5/9 [00:11<00:05,  1.37s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (104 Steps) (loss=0.84833):  56%|█████▌    | 5/9 [00:12<00:05,  1.37s/it]\n",
      "[Epoch 11] Training (104 Steps) (loss=0.84833):  67%|██████▋   | 6/9 [00:12<00:03,  1.12s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (105 Steps) (loss=0.80984):  67%|██████▋   | 6/9 [00:13<00:03,  1.12s/it]\n",
      "[Epoch 11] Training (105 Steps) (loss=0.80984):  78%|███████▊  | 7/9 [00:13<00:01,  1.05it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (106 Steps) (loss=0.92097):  78%|███████▊  | 7/9 [00:13<00:01,  1.05it/s]\n",
      "[Epoch 11] Training (106 Steps) (loss=0.92097):  89%|████████▉ | 8/9 [00:13<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (107 Steps) (loss=0.89886):  89%|████████▉ | 8/9 [00:14<00:00,  1.18it/s]\n",
      "[Epoch 11] Training (107 Steps) (loss=0.89886): 100%|██████████| 9/9 [00:14<00:00,  1.29it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 11] Training (107 Steps) (loss=0.89886): 100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (108 Steps) (loss=0.89325):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 12] Training (108 Steps) (loss=0.89325):  11%|█         | 1/9 [00:09<01:13,  9.21s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (109 Steps) (loss=0.89982):  11%|█         | 1/9 [00:09<01:13,  9.21s/it]\n",
      "[Epoch 12] Training (109 Steps) (loss=0.89982):  22%|██▏       | 2/9 [00:09<00:29,  4.17s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (110 Steps) (loss=0.82849):  22%|██▏       | 2/9 [00:10<00:29,  4.17s/it]\n",
      "[Epoch 12] Training (110 Steps) (loss=0.82849):  33%|███▎      | 3/9 [00:10<00:15,  2.55s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:39:44. Total running time: 4min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        2            239.298           0          0        0.467775       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (111 Steps) (loss=0.78532):  33%|███▎      | 3/9 [00:11<00:15,  2.55s/it]\n",
      "[Epoch 12] Training (111 Steps) (loss=0.78532):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (112 Steps) (loss=0.86703):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "[Epoch 12] Training (112 Steps) (loss=0.86703):  56%|█████▌    | 5/9 [00:11<00:05,  1.38s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (113 Steps) (loss=0.96170):  56%|█████▌    | 5/9 [00:12<00:05,  1.38s/it]\n",
      "[Epoch 12] Training (113 Steps) (loss=0.96170):  67%|██████▋   | 6/9 [00:12<00:03,  1.13s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (114 Steps) (loss=0.92320):  67%|██████▋   | 6/9 [00:13<00:03,  1.13s/it]\n",
      "[Epoch 12] Training (114 Steps) (loss=0.92320):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (115 Steps) (loss=0.95785):  78%|███████▊  | 7/9 [00:13<00:01,  1.03it/s]\n",
      "[Epoch 12] Training (115 Steps) (loss=0.95785):  89%|████████▉ | 8/9 [00:13<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (116 Steps) (loss=0.83229):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 12] Training (116 Steps) (loss=0.83229): 100%|██████████| 9/9 [00:14<00:00,  1.27it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 12] Training (116 Steps) (loss=0.83229): 100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (117 Steps) (loss=0.67463):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 13] Training (117 Steps) (loss=0.67463):  11%|█         | 1/9 [00:09<01:13,  9.24s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (118 Steps) (loss=1.16991):  11%|█         | 1/9 [00:09<01:13,  9.24s/it]\n",
      "[Epoch 13] Training (118 Steps) (loss=1.16991):  22%|██▏       | 2/9 [00:09<00:29,  4.18s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (119 Steps) (loss=0.85906):  22%|██▏       | 2/9 [00:10<00:29,  4.18s/it]\n",
      "[Epoch 13] Training (119 Steps) (loss=0.85906):  33%|███▎      | 3/9 [00:10<00:15,  2.56s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (120 Steps) (loss=0.96237):  33%|███▎      | 3/9 [00:11<00:15,  2.56s/it]\n",
      "[Epoch 13] Training (120 Steps) (loss=0.96237):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (121 Steps) (loss=0.74099):  44%|████▍     | 4/9 [00:11<00:08,  1.80s/it]\n",
      "[Epoch 13] Training (121 Steps) (loss=0.74099):  56%|█████▌    | 5/9 [00:11<00:05,  1.38s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (122 Steps) (loss=0.89587):  56%|█████▌    | 5/9 [00:12<00:05,  1.38s/it]\n",
      "[Epoch 13] Training (122 Steps) (loss=0.89587):  67%|██████▋   | 6/9 [00:12<00:03,  1.13s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (123 Steps) (loss=0.83569):  67%|██████▋   | 6/9 [00:13<00:03,  1.13s/it]\n",
      "[Epoch 13] Training (123 Steps) (loss=0.83569):  78%|███████▊  | 7/9 [00:13<00:01,  1.04it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (124 Steps) (loss=0.87271):  78%|███████▊  | 7/9 [00:13<00:01,  1.04it/s]\n",
      "[Epoch 13] Training (124 Steps) (loss=0.87271):  89%|████████▉ | 8/9 [00:13<00:00,  1.16it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (125 Steps) (loss=0.79212):  89%|████████▉ | 8/9 [00:14<00:00,  1.16it/s]\n",
      "[Epoch 13] Training (125 Steps) (loss=0.79212): 100%|██████████| 9/9 [00:14<00:00,  1.27it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 13] Training (125 Steps) (loss=0.79212): 100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (126 Steps) (loss=0.86195):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 14] Training (126 Steps) (loss=0.86195):  11%|█         | 1/9 [00:09<01:17,  9.69s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (127 Steps) (loss=0.84918):  11%|█         | 1/9 [00:10<01:17,  9.69s/it]\n",
      "[Epoch 14] Training (127 Steps) (loss=0.84918):  22%|██▏       | 2/9 [00:10<00:30,  4.39s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:40:14. Total running time: 5min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        2            239.298           0          0        0.467775       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (128 Steps) (loss=0.74763):  22%|██▏       | 2/9 [00:11<00:30,  4.39s/it]\n",
      "[Epoch 14] Training (128 Steps) (loss=0.74763):  33%|███▎      | 3/9 [00:11<00:16,  2.69s/it]\n",
      "2025-10-16 21:40:14,603\tWARNING syncer.py:585 -- Last sync command failed: Sync process failed: GetFileInfo() yielded path 'C:/Users/User/ray_results/AICUP_training', which is outside base dir 'C:\\Users\\User\\ray_results\\AICUP_training'\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (129 Steps) (loss=0.77878):  33%|███▎      | 3/9 [00:11<00:16,  2.69s/it]\n",
      "[Epoch 14] Training (129 Steps) (loss=0.77878):  44%|████▍     | 4/9 [00:11<00:09,  1.90s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (130 Steps) (loss=0.80342):  44%|████▍     | 4/9 [00:12<00:09,  1.90s/it]\n",
      "[Epoch 14] Training (130 Steps) (loss=0.80342):  56%|█████▌    | 5/9 [00:12<00:05,  1.47s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (131 Steps) (loss=0.97991):  56%|█████▌    | 5/9 [00:13<00:05,  1.47s/it]\n",
      "[Epoch 14] Training (131 Steps) (loss=0.97991):  67%|██████▋   | 6/9 [00:13<00:03,  1.21s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (132 Steps) (loss=0.88042):  67%|██████▋   | 6/9 [00:13<00:03,  1.21s/it]\n",
      "[Epoch 14] Training (132 Steps) (loss=0.88042):  78%|███████▊  | 7/9 [00:13<00:02,  1.04s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (133 Steps) (loss=0.72081):  78%|███████▊  | 7/9 [00:14<00:02,  1.04s/it]\n",
      "[Epoch 14] Training (133 Steps) (loss=0.72081):  89%|████████▉ | 8/9 [00:14<00:00,  1.06it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (134 Steps) (loss=0.77928):  89%|████████▉ | 8/9 [00:15<00:00,  1.06it/s]\n",
      "[Epoch 14] Training (134 Steps) (loss=0.77928): 100%|██████████| 9/9 [00:15<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 14] Training (134 Steps) (loss=0.77928): 100%|██████████| 9/9 [00:15<00:00,  1.76s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (135 Steps) (loss=0.90214):   0%|          | 0/9 [00:10<?, ?it/s]\n",
      "[Epoch 15] Training (135 Steps) (loss=0.90214):  11%|█         | 1/9 [00:10<01:20, 10.12s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (136 Steps) (loss=0.93185):  11%|█         | 1/9 [00:11<01:20, 10.12s/it]\n",
      "[Epoch 15] Training (136 Steps) (loss=0.93185):  22%|██▏       | 2/9 [00:11<00:32,  4.71s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (137 Steps) (loss=0.89394):  22%|██▏       | 2/9 [00:11<00:32,  4.71s/it]\n",
      "[Epoch 15] Training (137 Steps) (loss=0.89394):  33%|███▎      | 3/9 [00:11<00:17,  2.96s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (138 Steps) (loss=0.87185):  33%|███▎      | 3/9 [00:12<00:17,  2.96s/it]\n",
      "[Epoch 15] Training (138 Steps) (loss=0.87185):  44%|████▍     | 4/9 [00:12<00:10,  2.17s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (139 Steps) (loss=0.76190):  44%|████▍     | 4/9 [00:14<00:10,  2.17s/it]\n",
      "[Epoch 15] Training (139 Steps) (loss=0.76190):  56%|█████▌    | 5/9 [00:14<00:07,  1.80s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (140 Steps) (loss=0.77528):  56%|█████▌    | 5/9 [00:14<00:07,  1.80s/it]\n",
      "[Epoch 15] Training (140 Steps) (loss=0.77528):  67%|██████▋   | 6/9 [00:14<00:04,  1.45s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (141 Steps) (loss=0.85720):  67%|██████▋   | 6/9 [00:15<00:04,  1.45s/it]\n",
      "[Epoch 15] Training (141 Steps) (loss=0.85720):  78%|███████▊  | 7/9 [00:15<00:02,  1.29s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (142 Steps) (loss=0.75179):  78%|███████▊  | 7/9 [00:16<00:02,  1.29s/it]\n",
      "[Epoch 15] Training (142 Steps) (loss=0.75179):  89%|████████▉ | 8/9 [00:16<00:01,  1.22s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (143 Steps) (loss=0.82975):  89%|████████▉ | 8/9 [00:17<00:01,  1.22s/it]\n",
      "[Epoch 15] Training (143 Steps) (loss=0.82975): 100%|██████████| 9/9 [00:17<00:00,  1.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 15] Training (143 Steps) (loss=0.82975): 100%|██████████| 9/9 [00:18<00:00,  2.05s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:40:44. Total running time: 5min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        2            239.298           0          0        0.467775       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (144 / 10 Steps):   0%|          | 0/3 [00:06<?, ?it/s]        \n",
      "Validate (144 / 10 Steps):  33%|███▎      | 1/3 [00:06<00:13,  6.66s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (144 / 10 Steps):  33%|███▎      | 1/3 [00:08<00:13,  6.66s/it]\n",
      "Validate (144 / 10 Steps):  67%|██████▋   | 2/3 [00:08<00:03,  3.97s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (144 / 10 Steps):  67%|██████▋   | 2/3 [00:10<00:03,  3.97s/it]\n",
      "Validate (144 / 10 Steps): 100%|██████████| 3/3 [00:10<00:00,  3.06s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (144 / 10 Steps): 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\best_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Best Model Was Saved ! Current Best Avg. Dice: 0.5090456008911133 Current Avg. Dice: 0.5090456008911133\n",
      "Training finished iteration 3 at 2025-10-16 21:40:52. Total running time: 5min 38s\n",
      "╭──────────────────────────────╮\n",
      "│ Training result              │\n",
      "├──────────────────────────────┤\n",
      "│ time_this_iter_s     94.0455 │\n",
      "│ time_total_s         333.344 │\n",
      "│ training_iteration         3 │\n",
      "│ esc                        0 │\n",
      "│ tt_dice                    0 │\n",
      "│ tt_iou                     0 │\n",
      "│ val_bst_acc          0.50905 │\n",
      "╰──────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\final_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.5090456008911133 Current Avg. Dice: 0.5090456008911133\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (144 Steps) (loss=0.91688):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 16] Training (144 Steps) (loss=0.91688):  11%|█         | 1/9 [00:09<01:17,  9.63s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (145 Steps) (loss=0.75367):  11%|█         | 1/9 [00:10<01:17,  9.63s/it]\n",
      "[Epoch 16] Training (145 Steps) (loss=0.75367):  22%|██▏       | 2/9 [00:10<00:30,  4.35s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (146 Steps) (loss=0.84587):  22%|██▏       | 2/9 [00:10<00:30,  4.35s/it]\n",
      "[Epoch 16] Training (146 Steps) (loss=0.84587):  33%|███▎      | 3/9 [00:10<00:15,  2.65s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (147 Steps) (loss=0.81088):  33%|███▎      | 3/9 [00:11<00:15,  2.65s/it]\n",
      "[Epoch 16] Training (147 Steps) (loss=0.81088):  44%|████▍     | 4/9 [00:11<00:09,  1.86s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (148 Steps) (loss=0.84929):  44%|████▍     | 4/9 [00:12<00:09,  1.86s/it]\n",
      "[Epoch 16] Training (148 Steps) (loss=0.84929):  56%|█████▌    | 5/9 [00:12<00:05,  1.44s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (149 Steps) (loss=0.82664):  56%|█████▌    | 5/9 [00:12<00:05,  1.44s/it]\n",
      "[Epoch 16] Training (149 Steps) (loss=0.82664):  67%|██████▋   | 6/9 [00:12<00:03,  1.19s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (150 Steps) (loss=0.94852):  67%|██████▋   | 6/9 [00:13<00:03,  1.19s/it]\n",
      "[Epoch 16] Training (150 Steps) (loss=0.94852):  78%|███████▊  | 7/9 [00:13<00:02,  1.04s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (151 Steps) (loss=0.77651):  78%|███████▊  | 7/9 [00:14<00:02,  1.04s/it]\n",
      "[Epoch 16] Training (151 Steps) (loss=0.77651):  89%|████████▉ | 8/9 [00:14<00:00,  1.08it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (152 Steps) (loss=0.84138):  89%|████████▉ | 8/9 [00:15<00:00,  1.08it/s]\n",
      "[Epoch 16] Training (152 Steps) (loss=0.84138): 100%|██████████| 9/9 [00:15<00:00,  1.20it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 16] Training (152 Steps) (loss=0.84138): 100%|██████████| 9/9 [00:15<00:00,  1.74s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:41:14. Total running time: 6min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        3            333.344           0          0        0.509046       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (153 Steps) (loss=0.87978):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 17] Training (153 Steps) (loss=0.87978):  11%|█         | 1/9 [00:09<01:13,  9.18s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (154 Steps) (loss=0.83945):  11%|█         | 1/9 [00:09<01:13,  9.18s/it]\n",
      "[Epoch 17] Training (154 Steps) (loss=0.83945):  22%|██▏       | 2/9 [00:09<00:28,  4.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (155 Steps) (loss=0.80311):  22%|██▏       | 2/9 [00:10<00:28,  4.14s/it]\n",
      "[Epoch 17] Training (155 Steps) (loss=0.80311):  33%|███▎      | 3/9 [00:10<00:15,  2.53s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (156 Steps) (loss=0.81297):  33%|███▎      | 3/9 [00:11<00:15,  2.53s/it]\n",
      "[Epoch 17] Training (156 Steps) (loss=0.81297):  44%|████▍     | 4/9 [00:11<00:08,  1.78s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (157 Steps) (loss=1.17346):  44%|████▍     | 4/9 [00:11<00:08,  1.78s/it]\n",
      "[Epoch 17] Training (157 Steps) (loss=1.17346):  56%|█████▌    | 5/9 [00:11<00:05,  1.36s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (158 Steps) (loss=0.74876):  56%|█████▌    | 5/9 [00:12<00:05,  1.36s/it]\n",
      "[Epoch 17] Training (158 Steps) (loss=0.74876):  67%|██████▋   | 6/9 [00:12<00:03,  1.11s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (159 Steps) (loss=0.94341):  67%|██████▋   | 6/9 [00:12<00:03,  1.11s/it]\n",
      "[Epoch 17] Training (159 Steps) (loss=0.94341):  78%|███████▊  | 7/9 [00:12<00:01,  1.05it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (160 Steps) (loss=0.76395):  78%|███████▊  | 7/9 [00:13<00:01,  1.05it/s]\n",
      "[Epoch 17] Training (160 Steps) (loss=0.76395):  89%|████████▉ | 8/9 [00:13<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (161 Steps) (loss=0.82132):  89%|████████▉ | 8/9 [00:14<00:00,  1.18it/s]\n",
      "[Epoch 17] Training (161 Steps) (loss=0.82132): 100%|██████████| 9/9 [00:14<00:00,  1.29it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 17] Training (161 Steps) (loss=0.82132): 100%|██████████| 9/9 [00:14<00:00,  1.64s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (162 Steps) (loss=0.76254):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 18] Training (162 Steps) (loss=0.76254):  11%|█         | 1/9 [00:09<01:13,  9.22s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (163 Steps) (loss=0.74626):  11%|█         | 1/9 [00:09<01:13,  9.22s/it]\n",
      "[Epoch 18] Training (163 Steps) (loss=0.74626):  22%|██▏       | 2/9 [00:09<00:29,  4.16s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (164 Steps) (loss=0.85031):  22%|██▏       | 2/9 [00:10<00:29,  4.16s/it]\n",
      "[Epoch 18] Training (164 Steps) (loss=0.85031):  33%|███▎      | 3/9 [00:10<00:15,  2.54s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (165 Steps) (loss=0.76561):  33%|███▎      | 3/9 [00:11<00:15,  2.54s/it]\n",
      "[Epoch 18] Training (165 Steps) (loss=0.76561):  44%|████▍     | 4/9 [00:11<00:09,  1.85s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (166 Steps) (loss=0.78873):  44%|████▍     | 4/9 [00:12<00:09,  1.85s/it]\n",
      "[Epoch 18] Training (166 Steps) (loss=0.78873):  56%|█████▌    | 5/9 [00:12<00:05,  1.46s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (167 Steps) (loss=0.76641):  56%|█████▌    | 5/9 [00:12<00:05,  1.46s/it]\n",
      "[Epoch 18] Training (167 Steps) (loss=0.76641):  67%|██████▋   | 6/9 [00:12<00:03,  1.22s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (168 Steps) (loss=0.76716):  67%|██████▋   | 6/9 [00:13<00:03,  1.22s/it]\n",
      "[Epoch 18] Training (168 Steps) (loss=0.76716):  78%|███████▊  | 7/9 [00:13<00:02,  1.04s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (169 Steps) (loss=0.86524):  78%|███████▊  | 7/9 [00:14<00:02,  1.04s/it]\n",
      "[Epoch 18] Training (169 Steps) (loss=0.86524):  89%|████████▉ | 8/9 [00:14<00:00,  1.10it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (170 Steps) (loss=0.83291):  89%|████████▉ | 8/9 [00:14<00:00,  1.10it/s]\n",
      "[Epoch 18] Training (170 Steps) (loss=0.83291): 100%|██████████| 9/9 [00:14<00:00,  1.18it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 18] Training (170 Steps) (loss=0.83291): 100%|██████████| 9/9 [00:15<00:00,  1.71s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:41:44. Total running time: 6min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        3            333.344           0          0        0.509046       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (171 Steps) (loss=0.72509):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 19] Training (171 Steps) (loss=0.72509):  11%|█         | 1/9 [00:09<01:18,  9.79s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (172 Steps) (loss=0.81480):  11%|█         | 1/9 [00:10<01:18,  9.79s/it]\n",
      "[Epoch 19] Training (172 Steps) (loss=0.81480):  22%|██▏       | 2/9 [00:10<00:31,  4.56s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (173 Steps) (loss=0.89624):  22%|██▏       | 2/9 [00:11<00:31,  4.56s/it]\n",
      "[Epoch 19] Training (173 Steps) (loss=0.89624):  33%|███▎      | 3/9 [00:11<00:17,  2.94s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (174 Steps) (loss=0.98202):  33%|███▎      | 3/9 [00:12<00:17,  2.94s/it]\n",
      "[Epoch 19] Training (174 Steps) (loss=0.98202):  44%|████▍     | 4/9 [00:12<00:11,  2.28s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (175 Steps) (loss=0.71054):  44%|████▍     | 4/9 [00:14<00:11,  2.28s/it]\n",
      "[Epoch 19] Training (175 Steps) (loss=0.71054):  56%|█████▌    | 5/9 [00:14<00:07,  1.89s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (176 Steps) (loss=0.78689):  56%|█████▌    | 5/9 [00:15<00:07,  1.89s/it]\n",
      "[Epoch 19] Training (176 Steps) (loss=0.78689):  67%|██████▋   | 6/9 [00:15<00:04,  1.56s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (177 Steps) (loss=0.85766):  67%|██████▋   | 6/9 [00:16<00:04,  1.56s/it]\n",
      "[Epoch 19] Training (177 Steps) (loss=0.85766):  78%|███████▊  | 7/9 [00:16<00:02,  1.35s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (178 Steps) (loss=0.76831):  78%|███████▊  | 7/9 [00:17<00:02,  1.35s/it]\n",
      "[Epoch 19] Training (178 Steps) (loss=0.76831):  89%|████████▉ | 8/9 [00:17<00:01,  1.27s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (179 Steps) (loss=0.76679):  89%|████████▉ | 8/9 [00:18<00:01,  1.27s/it]\n",
      "[Epoch 19] Training (179 Steps) (loss=0.76679): 100%|██████████| 9/9 [00:18<00:00,  1.18s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 19] Training (179 Steps) (loss=0.76679): 100%|██████████| 9/9 [00:18<00:00,  2.09s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Training (X / X Steps) (loss=X.X):   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (180 Steps) (loss=0.72551):   0%|          | 0/9 [00:09<?, ?it/s]\n",
      "[Epoch 20] Training (180 Steps) (loss=0.72551):  11%|█         | 1/9 [00:09<01:19,  9.92s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (181 Steps) (loss=0.76247):  11%|█         | 1/9 [00:10<01:19,  9.92s/it]\n",
      "[Epoch 20] Training (181 Steps) (loss=0.76247):  22%|██▏       | 2/9 [00:10<00:32,  4.58s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (182 Steps) (loss=0.80974):  22%|██▏       | 2/9 [00:11<00:32,  4.58s/it]\n",
      "[Epoch 20] Training (182 Steps) (loss=0.80974):  33%|███▎      | 3/9 [00:11<00:18,  3.03s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (183 Steps) (loss=0.90110):  33%|███▎      | 3/9 [00:12<00:18,  3.03s/it]\n",
      "[Epoch 20] Training (183 Steps) (loss=0.90110):  44%|████▍     | 4/9 [00:12<00:11,  2.25s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (184 Steps) (loss=0.72638):  44%|████▍     | 4/9 [00:13<00:11,  2.25s/it]\n",
      "[Epoch 20] Training (184 Steps) (loss=0.72638):  56%|█████▌    | 5/9 [00:13<00:07,  1.78s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (185 Steps) (loss=0.82865):  56%|█████▌    | 5/9 [00:14<00:07,  1.78s/it]\n",
      "[Epoch 20] Training (185 Steps) (loss=0.82865):  67%|██████▋   | 6/9 [00:14<00:04,  1.52s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (186 Steps) (loss=0.87352):  67%|██████▋   | 6/9 [00:16<00:04,  1.52s/it]\n",
      "[Epoch 20] Training (186 Steps) (loss=0.87352):  78%|███████▊  | 7/9 [00:16<00:02,  1.40s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (187 Steps) (loss=0.79291):  78%|███████▊  | 7/9 [00:17<00:02,  1.40s/it]\n",
      "[Epoch 20] Training (187 Steps) (loss=0.79291):  89%|████████▉ | 8/9 [00:17<00:01,  1.25s/it]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:42:14. Total running time: 7min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        3            333.344           0          0        0.509046       0 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (188 Steps) (loss=0.71673):  89%|████████▉ | 8/9 [00:17<00:01,  1.25s/it]\n",
      "[Epoch 20] Training (188 Steps) (loss=0.71673): 100%|██████████| 9/9 [00:17<00:00,  1.10s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "[Epoch 20] Training (188 Steps) (loss=0.71673): 100%|██████████| 9/9 [00:18<00:00,  2.06s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (X / X Steps) (dice=X.X):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (189 / 10 Steps):   0%|          | 0/3 [00:06<?, ?it/s]        \n",
      "Validate (189 / 10 Steps):  33%|███▎      | 1/3 [00:06<00:13,  6.82s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (189 / 10 Steps):  33%|███▎      | 1/3 [00:08<00:13,  6.82s/it]\n",
      "Validate (189 / 10 Steps):  67%|██████▋   | 2/3 [00:08<00:04,  4.00s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (189 / 10 Steps):  67%|██████▋   | 2/3 [00:10<00:04,  4.00s/it]\n",
      "Validate (189 / 10 Steps): 100%|██████████| 3/3 [00:10<00:00,  3.14s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "Validate (189 / 10 Steps): 100%|██████████| 3/3 [00:11<00:00,  3.88s/it]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Early stop count:  1\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.5090456008911133 Current Avg. Dice: 0.5062622427940369\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\final_model.pth\n",
      "Training finished iteration 4 at 2025-10-16 21:42:30. Total running time: 7min 16s\n",
      "╭──────────────────────────────╮\n",
      "│ Training result              │\n",
      "├──────────────────────────────┤\n",
      "│ time_this_iter_s     97.8726 │\n",
      "│ time_total_s         431.216 │\n",
      "│ training_iteration         4 │\n",
      "│ esc                        1 │\n",
      "│ tt_dice                    0 │\n",
      "│ tt_iou                     0 │\n",
      "│ val_bst_acc          0.50905 │\n",
      "╰──────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Saving checkpoint .\\models\\final_model.pth\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Final Model Was Saved ! Current Best Avg. Dice: 0.5090456008911133 Current Avg. Dice: 0.5062622427940369\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m cuda is available\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m model: cotr\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m   + Number of Backbone Params: 20.50(e6)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m   + Number of Transformer Params: 9.32(e6)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m loss: dice ce loss\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m optimzer: AdamW\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m {'lr': 0.0005, 'weight_decay': 0.0005}\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m => loaded checkpoint '.\\models\\best_model.pth' (epoch 16) (bestacc 0.5090456008911133) (early stop count 0)\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m load json from d:\\Felix\\ML\\Code\\CardiacSegV2\\exps\\data_dicts\\chgh\\AICUP_training.json\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m train files (9): ['patient0011', 'patient0012', 'patient0013', 'patient0014', 'patient0015', 'patient0016', 'patient0017', 'patient0018', 'patient0019']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m val files (3): ['patient0048', 'patient0049', 'patient0050']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m test files (3): ['patient0001', 'patient0002', 'patient0003']\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer data: {'image': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0001.nii.gz', 'label': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0001_gt.nii.gz'}\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer time: 1.7200660705566406 sec\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m use post process infer\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[3.0269600e+05 8.9159000e+04 1.5244029e+07 2.7139100e+05]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [3.2400000e+02 9.5800000e+02 1.5897237e+07 8.7560000e+03]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.0000000e+00 0.0000000e+00 1.5907189e+07 8.6000000e+01]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test time aug:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.6267374  0.06253619 0.        ]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.4563857  0.03227735 0.        ]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:42:44. Total running time: 7min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        4            431.216           0          0        0.509046       1 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[1.7301870e+06 4.8106400e+05 8.5644288e+07 1.5355660e+06]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [1.6580000e+03 5.6480000e+03 8.9334584e+07 4.9216000e+04]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.0000000e+00 0.0000000e+00 8.9390640e+07 4.6800000e+02]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test original:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.63180155 0.05699749 0.        ]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.46177626 0.02933475 0.        ]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m sensitivity: [0.52979726 0.03259032 0.        ]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m specificity: [0.9944144  0.99993676 1.        ]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer data: {'image': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0002.nii.gz', 'label': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0002_gt.nii.gz'}\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer time: 4.722475051879883 sec\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m use post process infer\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m invalid value encountered in divide\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[3.0877800e+05 1.2293400e+05 1.4880592e+07 2.6602100e+05]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [7.4800000e+02 2.3260000e+03 1.5565593e+07 9.6580000e+03]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.0000000e+00 1.0000000e+00 1.5578324e+07 0.0000000e+00]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test time aug:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.6135611  0.11097923        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.44254464 0.05874961        nan]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:43:14. Total running time: 8min 0s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        4            431.216           0          0        0.509046       1 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[2.05888600e+06 7.77672000e+05 9.78862160e+07 1.77552800e+06]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [5.45500000e+03 1.54560000e+04 1.02414592e+08 6.28010000e+04]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.00000000e+00 8.00000000e+00 1.02498296e+08 0.00000000e+00]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test original:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.6172674  0.12235469        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.44641122 0.0651639         nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m sensitivity: [0.53694934 0.07991971        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m specificity: [0.99211794 0.9998491  0.99999994]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer data: {'image': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0003.nii.gz', 'label': 'd:\\\\Felix\\\\ML\\\\Code\\\\CardiacSegV2\\\\dataset\\\\chgh\\\\patient0003_gt.nii.gz'}\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer time: 1.9432923793792725 sec\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m use post process infer\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[3.0039700e+05 9.8781000e+04 1.5770353e+07 3.1575100e+05]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [7.4000000e+02 1.3700000e+03 1.6471159e+07 1.2013000e+04]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.0000000e+00 1.0000000e+00 1.6485281e+07 0.0000000e+00]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test time aug:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.59172523 0.09957613        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.4201774 0.0523968       nan]\n",
      "Trial status: 1 RUNNING\n",
      "Current time: 2025-10-16 21:43:44. Total running time: 8min 30s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status     exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc     esc │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   RUNNING    ...'AICUP_training'}        4            431.216           0          0        0.509046       1 │\n",
      "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "Training finished iteration 5 at 2025-10-16 21:44:07. Total running time: 8min 54s\n",
      "╭───────────────────────────────╮\n",
      "│ Training result               │\n",
      "├───────────────────────────────┤\n",
      "│ time_this_iter_s      97.3747 │\n",
      "│ time_total_s          528.591 │\n",
      "│ training_iteration          5 │\n",
      "│ inf_dice             0.315433 │\n",
      "│ inf_iou              0.218944 │\n",
      "│ inf_time              2.79528 │\n",
      "│ tt_dice               0.31256 │\n",
      "│ tt_iou               0.216607 │\n",
      "│ val_bst_acc           0.50905 │\n",
      "╰───────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Confusion_Vals： [[1.5597560e+06 5.0084800e+05 8.1236864e+07 1.6371900e+06]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [3.8470000e+03 6.6000000e+03 8.4861896e+07 6.2314000e+04]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m  [0.0000000e+00 8.0000000e+00 8.4934648e+07 0.0000000e+00]]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m infer test original:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m dice: [0.5933395  0.10043731        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m iou: [0.42180717 0.05287391        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m sensitivity: [0.48788938 0.05814604        nan]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m specificity: [0.9938725 0.9999222 0.9999999]\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m eval result:\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg tt dice: 0.31255957\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg tt iou: 0.21660732\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg inf dice: 0.31543303\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg inf iou: 0.21894391\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg inf sensitivity: 0.25630492\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg inf specificity: 0.9977903\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m avg inf time: 2.7952778339385986\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m      patientId  tt_diceC  tt_diceAO  tt_diceCA   tt_iouC  tt_iouAO  tt_iouCA  inf_diceC  inf_diceAO  inf_diceCA  inf_iouC  inf_iouAO  inf_iouCA  inf_sensitivityC  inf_sensitivityAO  inf_sensitivityCA  inf_specificityC  inf_specificityAO  inf_specificityCA  inf_time\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m 0  patient0001  0.626737   0.062536        0.0  0.456386  0.032277       0.0   0.631802    0.056997         0.0  0.461776   0.029335        0.0          0.529797           0.032590                0.0          0.994414           0.999937                1.0  1.720066\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m 1  patient0002  0.613561   0.110979        NaN  0.442545  0.058750       NaN   0.617267    0.122355         NaN  0.446411   0.065164        NaN          0.536949           0.079920                NaN          0.992118           0.999849                1.0  4.722475\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m 2  patient0003  0.591725   0.099576        NaN  0.420177  0.052397       NaN   0.593340    0.100437         NaN  0.421807   0.052874        NaN          0.487889           0.058146                NaN          0.993873           0.999922                1.0  1.943292\n",
      "Training completed after 5 iterations at 2025-10-16 21:44:07. Total running time: 8min 54s\n",
      "\n",
      "2025-10-16 21:44:07,854\tWARNING tune.py:1122 -- Trial Runner checkpointing failed: Sync process failed: GetFileInfo() yielded path 'C:/Users/User/ray_results/AICUP_training', which is outside base dir 'C:\\Users\\User\\ray_results\\AICUP_training'\n",
      "Trial status: 1 TERMINATED\n",
      "Current time: 2025-10-16 21:44:07. Total running time: 8min 54s\n",
      "Logical resource usage: 1.0/20 CPUs, 1.0/1 GPUs\n",
      "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
      "│ Trial name         status       exp                      iter     total time (s)     tt_dice     tt_iou     val_bst_acc │\n",
      "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ main_f1d18_00000   TERMINATED   ...'AICUP_training'}        5            528.591     0.31256   0.216607        0.509046 │\n",
      "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/User/ray_results/AICUP_training/main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13', which is outside base dir 'C:\\Users\\User\\ray_results\\AICUP_training\\main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/User/ray_results/AICUP_training/main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13', which is outside base dir 'C:\\Users\\User\\ray_results\\AICUP_training\\main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Caught sync error: Sync process failed: GetFileInfo() yielded path 'C:/Users/User/ray_results/AICUP_training/main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13', which is outside base dir 'C:\\Users\\User\\ray_results\\AICUP_training\\main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13\\'. Retrying after sleeping for 1.0 seconds...\n",
      "\u001b[2m\u001b[36m(func pid=31264)\u001b[0m Could not upload checkpoint to d://\\Felix\\ML\\Code\\CardiacSegV2\\exps\\exps\\cotr\\chgh\\tune_results\\AICUP_training\\main_f1d18_00000_0_exp=exp_AICUP_training_2025-10-16_21-35-13 even after 3 retries.Please check if the credentials expired and that the remote filesystem is supported. For large checkpoints or artifacts, consider increasing `SyncConfig(sync_timeout)` (current value: 1800 seconds).\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✅ 訓練完成！\n",
      "最佳模型已儲存至: .\\models\\best_model.pth\n",
      "最終模型已儲存至: .\\models\\final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型 (Windows 版本)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 確保在正確的目錄\n",
    "original_dir = os.getcwd()\n",
    "os.chdir(workspace_dir)\n",
    "\n",
    "print(f\"當前工作目錄: {os.getcwd()}\")\n",
    "print(\"開始訓練...\\n\")\n",
    "\n",
    "# 建構訓練命令\n",
    "train_cmd = [\n",
    "    sys.executable, \"expers/tune.py\",\n",
    "    \"--tune_mode=train\",\n",
    "    f\"--exp_name={exp_name}\",\n",
    "    f\"--data_name={data_name}\",\n",
    "    f\"--data_dir={data_dir}\",\n",
    "    f\"--root_exp_dir={root_exp_dir}\",\n",
    "    f\"--model_name={model_name}\",\n",
    "    f\"--model_dir={model_dir}\",\n",
    "    f\"--log_dir={log_dir}\",\n",
    "    f\"--eval_dir={eval_dir}\",\n",
    "    \"--start_epoch=0\",\n",
    "    \"--val_every=5\",\n",
    "    \"--max_early_stop_count=2\",\n",
    "    \"--max_epoch=20\",\n",
    "    f\"--data_dicts_json={data_dicts_json}\",\n",
    "    \"--pin_memory\",\n",
    "    \"--out_channels=4\",\n",
    "    \"--patch_size=4\",\n",
    "    \"--feature_size=48\",\n",
    "    \"--drop_rate=0.1\",\n",
    "    \"--depths\", \"3\", \"3\", \"9\", \"3\",\n",
    "    \"--kernel_size\", \"7\",\n",
    "    \"--exp_rate\", \"4\",\n",
    "    \"--norm_name=layer\",\n",
    "    \"--a_min=-42\",\n",
    "    \"--a_max=423\",\n",
    "    \"--space_x=0.7\",\n",
    "    \"--space_y=0.7\",\n",
    "    \"--space_z=1.0\",\n",
    "    \"--roi_x=128\",\n",
    "    \"--roi_y=128\",\n",
    "    \"--roi_z=120\",\n",
    "    \"--optim=AdamW\",\n",
    "    \"--lr=5e-4\",\n",
    "    \"--weight_decay=5e-4\",\n",
    "    f\"--checkpoint={final_checkpoint}\",\n",
    "    \"--use_init_weights\",\n",
    "    \"--infer_post_process\"\n",
    "]\n",
    "\n",
    "print(\"執行命令:\")\n",
    "print(\" \".join(train_cmd))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 使用 Popen 來即時顯示輸出\n",
    "process = subprocess.Popen(\n",
    "    train_cmd,\n",
    "    cwd=workspace_dir,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# 即時打印輸出\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "\n",
    "# 等待程序完成\n",
    "return_code = process.wait()\n",
    "\n",
    "# 切回原始目錄\n",
    "os.chdir(original_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if return_code == 0:\n",
    "    print(\"\\n✅ 訓練完成！\")\n",
    "    print(f\"最佳模型已儲存至: {best_checkpoint}\")\n",
    "    print(f\"最終模型已儲存至: {final_checkpoint}\")\n",
    "else:\n",
    "    print(f\"\\n❌ 訓練失敗，錯誤碼: {return_code}\")\n",
    "    print(\"請查看上方的錯誤訊息以了解失敗原因\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21622af9",
   "metadata": {},
   "source": [
    "# 4. 測試訓練結果\n",
    "\n",
    "使用訓練好的模型進行測試評估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fdb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試模型 (Windows 版本)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 確保在正確的目錄\n",
    "original_dir = os.getcwd()\n",
    "os.chdir(workspace_dir)\n",
    "\n",
    "print(f\"當前工作目錄: {os.getcwd()}\")\n",
    "print(\"開始測試...\\n\")\n",
    "\n",
    "# 建構測試命令\n",
    "test_cmd = [\n",
    "    sys.executable, \"expers/tune.py\",\n",
    "    \"--tune_mode=test\",\n",
    "    f\"--exp_name={exp_name}\",\n",
    "    f\"--data_name={data_name}\",\n",
    "    f\"--data_dir={data_dir}\",\n",
    "    f\"--root_exp_dir={root_exp_dir}\",\n",
    "    f\"--model_name={model_name}\",\n",
    "    f\"--model_dir={model_dir}\",\n",
    "    f\"--log_dir={log_dir}\",\n",
    "    f\"--eval_dir={eval_dir}\",\n",
    "    f\"--data_dicts_json={data_dicts_json}\",\n",
    "    \"--pin_memory\",\n",
    "    \"--out_channels=4\",\n",
    "    \"--patch_size=4\",\n",
    "    \"--feature_size=48\",\n",
    "    \"--drop_rate=0.1\",\n",
    "    \"--depths\", \"3\", \"3\", \"9\", \"3\",\n",
    "    \"--kernel_size\", \"7\",\n",
    "    \"--exp_rate\", \"4\",\n",
    "    \"--norm_name=layer\",\n",
    "    \"--a_min=-42\",\n",
    "    \"--a_max=423\",\n",
    "    \"--space_x=0.7\",\n",
    "    \"--space_y=0.7\",\n",
    "    \"--space_z=1.0\",\n",
    "    \"--roi_x=128\",\n",
    "    \"--roi_y=128\",\n",
    "    \"--roi_z=128\",\n",
    "    \"--optim=AdamW\",\n",
    "    \"--lr=5e-4\",\n",
    "    \"--weight_decay=5e-4\",\n",
    "    f\"--checkpoint={final_checkpoint}\",\n",
    "    \"--use_init_weights\",\n",
    "    \"--infer_post_process\",\n",
    "    \"--resume_tuner\",\n",
    "    \"--save_eval_csv\",\n",
    "    \"--test_mode\"\n",
    "]\n",
    "\n",
    "print(\"執行命令:\")\n",
    "print(\" \".join(test_cmd))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# 使用 Popen 來即時顯示輸出\n",
    "process = subprocess.Popen(\n",
    "    test_cmd,\n",
    "    cwd=workspace_dir,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# 即時打印輸出\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "\n",
    "# 等待程序完成\n",
    "return_code = process.wait()\n",
    "\n",
    "# 切回原始目錄\n",
    "os.chdir(original_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if return_code == 0:\n",
    "    print(\"\\n✅ 測試完成！\")\n",
    "else:\n",
    "    print(f\"\\n❌ 測試失敗，錯誤碼: {return_code}\")\n",
    "    print(\"請查看上方的錯誤訊息以了解失敗原因\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
